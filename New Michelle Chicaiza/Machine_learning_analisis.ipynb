{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Librerías estándar y manipulación de archivos\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Manipulación de datos y operaciones básicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Reducción de dimensionalidad\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modelos de Machine Learning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Selección y validación de modelos\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict, GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Técnicas de balanceo de clases\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, roc_curve, auc\n",
    "\n",
    "# Configuraciones adicionales\n",
    "import warnings\n",
    "\n",
    "# Se ignoran los warnings en el notebook\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Se importan las librerias necesarias para el uso de pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Se define el dispositivo a utilizar\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print (device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (127335, 19)\n",
      "y_train shape: (127335,)\n",
      "X_test shape: (22097, 19)\n",
      "y_test shape: (22097,)\n",
      "X_train dtype: float64\n",
      "y_train dtype: bool\n",
      "X_test dtype: float64\n",
      "y_test dtype: bool\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    return joblib.load(file_path)\n",
    "\n",
    "# Listado de archivos\n",
    "file_names = [\n",
    "    \"X_test_P1-ALL-ADASYN.pkl\", \"X_test_P1-ALL.pkl\", \"X_test_P2-NOCONDITIONS.pkl\", \"X_test_P3-AGE.pkl\",\n",
    "    \"X_test_P4-TIME.pkl\", \"X_test_P5-HEALTHCENTRE.pkl\", \"X_train_P1-ALL-ADASYN.pkl\", \"X_train_P1-ALL.pkl\",\n",
    "    \"X_train_P2-NOCONDITIONS.pkl\", \"X_train_P3-AGE.pkl\", \"X_train_P4-TIME.pkl\", \"X_train_P5-HEALTHCENTRE.pkl\",\n",
    "    \"y_test_P1-ALL-ADASYN.pkl\", \"y_test_P1-ALL.pkl\", \"y_test_P2-NOCONDITIONS.pkl\", \"y_test_P3-AGE.pkl\",\n",
    "    \"y_test_P4-TIME.pkl\", \"y_test_P5-HEALTHCENTRE.pkl\", \"y_train_P1-ALL-ADASYN.pkl\", \"y_train_P1-ALL.pkl\",\n",
    "    \"y_train_P2-NOCONDITIONS.pkl\", \"y_train_P3-AGE.pkl\", \"y_train_P4-TIME.pkl\", \"y_train_P5-HEALTHCENTRE.pkl\"\n",
    "]\n",
    "\n",
    "# Se cargan los archivos en un diccionario\n",
    "data = {file_name: load_data(os.path.join(file_name)) for file_name in file_names}\n",
    "\n",
    "# Se extraen los datos de entrenamiento y prueba\n",
    "X_train = data[\"X_train_P1-ALL.pkl\"]\n",
    "y_train = data[\"y_train_P1-ALL.pkl\"]\n",
    "X_test = data[\"X_test_P1-ALL.pkl\"]\n",
    "y_test = data[\"y_test_P1-ALL.pkl\"]\n",
    "\n",
    "# Se verifica la forma de los datos\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Se verifica los tipos de datos\n",
    "print(f\"X_train dtype: {X_train.dtype}\")\n",
    "print(f\"y_train dtype: {y_train.dtype}\")\n",
    "print(f\"X_test dtype: {X_test.dtype}\")\n",
    "print(f\"y_test dtype: {y_test.dtype}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la funcion para grafiar la perdida por epoca\n",
    "def graficar_progreso(losses, inicio_folds, grado=3):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    # Gráfico original\n",
    "    plt.plot(range(1, len(losses) + 1), losses, marker='o', linestyle='-', color='blue', label='Pérdida Real')\n",
    "\n",
    "     # Marcar y anotar el inicio de cada fold\n",
    "    for i, inicio in enumerate(inicio_folds):\n",
    "        plt.axvline(x=inicio, color='black', linestyle='--', lw=1)\n",
    "        plt.text(inicio, max(losses)*0.95, f'Inicio Fold {i+1}', rotation=90, color='black', fontsize=12, fontweight='bold')\n",
    "\n",
    "    # Ajustando la curva de tendencia\n",
    "    z = np.polyfit(range(1, len(losses) + 1), losses, grado)  # Ajuste polinomial\n",
    "    p = np.poly1d(z)  # Creación de un polinomio\n",
    "    plt.plot(range(1, len(losses) + 1), p(range(1, len(losses) + 1)), \"r--\", label='Curva de Tendencia')  # Curva de tendencia en rojo\n",
    "\n",
    "    # Configuración del gráfico\n",
    "    plt.title('Pérdida por Época a través de los Folds')\n",
    "    plt.xlabel('Época Total')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la función para evaluar el modelo\n",
    "def evaluar_modelo_pytorch(model, X_train_tensor, y_train, X_test_tensor, y_test):\n",
    "    # Evaluación con datos de entrenamiento\n",
    "    y_pred = model(X_train_tensor).detach().cpu().numpy()\n",
    "    y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Cálculo de métricas para datos de entrenamiento\n",
    "    accuracy = accuracy_score(y_train, y_pred_bin)\n",
    "    precision = precision_score(y_train, y_pred_bin)\n",
    "    recall = recall_score(y_train, y_pred_bin)\n",
    "    f1 = f1_score(y_train, y_pred_bin)\n",
    "\n",
    "    # Visualización de métricas y gráficos para datos de entrenamiento\n",
    "    print('\\033[1m' + '.' * len(\"Resultados datos de entrenamiento:\") + '\\n' + \"Resultados datos de entrenamiento:\" + '\\033[0m')\n",
    "    print(f\"Accuracy (Datos de Train): {accuracy}\")\n",
    "    print(f\"Precision (Datos de Train): {precision}\")\n",
    "    print(f\"Recall (Datos de Train): {recall}\")\n",
    "    print(f\"F1 Score (Datos de Train): {f1}\")\n",
    "\n",
    "    # Gráficos para datos de entrenamiento\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    conf_matrix = confusion_matrix(y_train, y_pred_bin)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "                xticklabels=['Asiste', 'No-show'], yticklabels=['Asiste', 'No-show'])\n",
    "    axes[0].set_title('Matriz de Confusión (Datos de Train)')\n",
    "    axes[0].set_xlabel('Predicho')\n",
    "    axes[0].set_ylabel('Real')\n",
    "    print (conf_matrix)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "    axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_title('Curva ROC (Datos de Train)')\n",
    "    axes[1].set_xlabel('Tasa de Falsos Positivos')\n",
    "    axes[1].set_ylabel('Tasa de Verdaderos Positivos')\n",
    "    axes[1].legend(loc=\"lower right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluación con datos de prueba\n",
    "    y_pred_test = model(X_test_tensor).detach().cpu().numpy()\n",
    "    y_pred_test_bin = (y_pred_test > 0.5).astype(int)\n",
    "\n",
    "    # Cálculo de métricas para datos de prueba\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test_bin)\n",
    "    precision_test = precision_score(y_test, y_pred_test_bin)\n",
    "    recall_test = recall_score(y_test, y_pred_test_bin)\n",
    "    f1_test = f1_score(y_test, y_pred_test_bin)\n",
    "\n",
    "    # Visualización de métricas y gráficos para datos de prueba\n",
    "    print('\\033[1m' + '.' * len(\"Resultados datos de test:\") + '\\n' + \"Resultados datos de test:\" + '\\033[0m')\n",
    "    print(f\"Accuracy (Datos de Test): {accuracy_test}\")\n",
    "    print(f\"Precision (Datos de Test): {precision_test}\")\n",
    "    print(f\"Recall (Datos de Test): {recall_test}\")\n",
    "    print(f\"F1 Score (Datos de Test): {f1_test}\")\n",
    "\n",
    "    # Gráficos para datos de prueba\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_pred_test_bin)\n",
    "    sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Reds', ax=axes[0],\n",
    "                xticklabels=['Asiste', 'No-show'], yticklabels=['Asiste', 'No-show'])\n",
    "    axes[0].set_title('Matriz de Confusión (Datos de Test)')\n",
    "    axes[0].set_xlabel('Predicho')\n",
    "    axes[0].set_ylabel('Real')\n",
    "    print (conf_matrix_test)\n",
    "\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_pred_test)\n",
    "    roc_auc_test = auc(fpr_test, tpr_test)\n",
    "    axes[1].plot(fpr_test, tpr_test, color='darkorange', lw=2, label=f'AUC = {roc_auc_test:.2f}')\n",
    "    axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_title('Curva ROC (Datos de Test)')\n",
    "    axes[1].set_xlabel('Tasa de Falsos Positivos')\n",
    "    axes[1].set_ylabel('Tasa de Verdaderos Positivos')\n",
    "    axes[1].legend(loc=\"lower right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for NeuralNet:\n\tsize mismatch for layer1.weight: copying a param with shape torch.Size([256, 14]) from checkpoint, the shape in current model is torch.Size([64, 19]).\n\tsize mismatch for layer1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layer2.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for layer2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layer3.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for layer3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn3.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn3.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.weight: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Se verifica si el modelo ya ha sido entrenado\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelo_pytorch.pth\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 43\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodelo_pytorch.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelo cargado desde el archivo.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Se definen los folds\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luiso\\anaconda3\\envs\\tfm_master\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for NeuralNet:\n\tsize mismatch for layer1.weight: copying a param with shape torch.Size([256, 14]) from checkpoint, the shape in current model is torch.Size([64, 19]).\n\tsize mismatch for layer1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for layer2.weight: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for layer2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layer3.weight: copying a param with shape torch.Size([256, 1024]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for layer3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bn3.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn3.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn3.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn3.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_layer.weight: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 64])."
     ]
    }
   ],
   "source": [
    "#Se verifica si el modelo ya ha sido entrenado\n",
    "class NeuralNet(nn.Module):\n",
    "    # Definir la arquitectura del modelo\n",
    "        def __init__(self, input_size):\n",
    "            super(NeuralNet, self).__init__()\n",
    "            self.layer1 = nn.Linear(input_size, 64) #  Capa oculta 1\n",
    "            self.bn1 = nn.BatchNorm1d(64) # Batch Normalization (BN), sirve para acelerar el entrenamiento y mejorar la precisión\n",
    "            self.relu1 = nn.ReLU() # Función de activación ReLU, sirve para introducir no linealidades en la red, permitiendo que el modelo aprenda relaciones más complejas\n",
    "                \n",
    "            self.layer2 = nn.Linear(64, 128) #  Capa oculta 2\n",
    "            self.relu2 = nn.ReLU()\n",
    "            self.bn2 = nn.BatchNorm1d(128) \n",
    "            self.dropout1 = nn.Dropout(0.5) # Dropout, sirve para evitar el sobreajuste desactivando aleatoriamente un porcentaje de las neuronas, en este caso, el 50%\n",
    "\n",
    "            self.layer3 = nn.Linear(64, 128) # Capa oculta 3\n",
    "            self.relu3 = nn.ReLU()\n",
    "            self.bn3 = nn.BatchNorm1d(64) \n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "            self.output_layer = nn.Linear(64, 1) # Capa de salida\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.bn1(self.layer1(x))  # Primero aplicar BN a la salida de la capa lineal\n",
    "            out = self.relu1(out)\n",
    "                \n",
    "            out = self.bn2(self.layer2(out)) \n",
    "            out = self.relu2(out)\n",
    "            out = self.dropout1(out)\n",
    "                \n",
    "            out = self.bn3(self.layer3(out))  \n",
    "            out = self.relu3(out)\n",
    "            out = self.dropout2(out)\n",
    "                \n",
    "            out = self.output_layer(out)\n",
    "            out = self.sigmoid(out)\n",
    "            return out\n",
    "# Instanciar el modelo\n",
    "model = NeuralNet(X_train.shape[1]).to(device)\n",
    "\n",
    "# Se verifica si el modelo ya ha sido entrenado\n",
    "if os.path.exists('modelo_pytorch.pth'):\n",
    "    model.load_state_dict(torch.load('modelo_pytorch.pth'))\n",
    "    print(\"Modelo cargado desde el archivo.\")\n",
    "else:\n",
    "    # Se definen los folds\n",
    "    skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    num_epochs = 100\n",
    "    fold_results = []\n",
    "    losses = []\n",
    "    inicio_folds = [1]  # La primera época siempre es el inicio del primer fold\n",
    "    epoca_actual = 0\n",
    "\n",
    "    criterion = nn.BCELoss() # Función de pérdida de entropía cruzada binaria\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4) # Optimizador Adam, es una versión avanzada de SGD que ajusta la tasa de aprendizaje de cada parámetro\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1) # Reducción de la tasa de aprendizaje\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skfolds.split(X_train, y_train)):\n",
    "        print(f'Comenzando el fold {fold+1}')\n",
    "\n",
    "        X_train_fold = X_train[train_index]\n",
    "        y_train_fold = y_train[train_index]\n",
    "        X_valid_fold = X_train[test_index]\n",
    "        y_valid_fold = y_train[test_index]\n",
    "\n",
    "        X_train_fold_tensor = torch.tensor(X_train_fold).float().to(device)\n",
    "        y_train_fold_tensor = torch.tensor(y_train_fold.to_numpy()[:, None]).float().to(device)\n",
    "        X_valid_fold_tensor = torch.tensor(X_valid_fold).float().to(device)\n",
    "        y_valid_fold_tensor = torch.tensor(y_valid_fold.to_numpy()[:, None]).float().to(device)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(X_train_fold_tensor, y_train_fold_tensor), batch_size=64, shuffle=True)\n",
    "        valid_loader = DataLoader(TensorDataset(X_valid_fold_tensor, y_valid_fold_tensor), batch_size=64)\n",
    "\n",
    "        epoch_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "            scheduler.step()\n",
    "\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in valid_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    val_losses.append(loss.item())\n",
    "\n",
    "            epoch_train_loss = torch.tensor(train_losses).mean().item()\n",
    "            epoch_val_loss = torch.tensor(val_losses).mean().item()\n",
    "            epoch_losses.append((epoch_train_loss, epoch_val_loss))\n",
    "            # Se añade la pérdida de validación a la lista global\n",
    "            losses.append(epoch_val_loss)\n",
    "            print(f'Fold {fold+1}, Epoch {epoch+1}, Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n",
    "\n",
    "        fold_results.append({\n",
    "            'fold': fold+1,\n",
    "            'epoch_losses': epoch_losses,\n",
    "        })\n",
    "        # Se añade el número de la última época de este fold al inicio de la lista\n",
    "        if fold < skfolds.n_splits - 1:\n",
    "            epoca_actual += num_epochs\n",
    "            inicio_folds.append(epoca_actual + 1)\n",
    "\n",
    "    # Se guarda el modelo\n",
    "    torch.save(model.state_dict(), 'modelo_pytorch.pth')\n",
    "\n",
    "# Se grafica el progreso de la pérdida a través de los folds\n",
    "graficar_progreso(losses, inicio_folds, grado=3)\n",
    "\n",
    "# Se convierten los datos de test a tensores\n",
    "X_test_tensor = torch.tensor(X_test).float().to(device)\n",
    "\n",
    "# Se evalúa el modelo entrenado\n",
    "evaluar_modelo_pytorch(model, X_train_fold_tensor, y_train_fold, X_test_tensor, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
